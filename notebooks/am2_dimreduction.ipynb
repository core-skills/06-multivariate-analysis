{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental notes, getting started\n",
    "\n",
    "We'll be using the same tools that we used last week for this session.\n",
    "\n",
    "- [pandas](pandas.pydata.org) for data handling (our dataframe library)\n",
    "- [seaborn](seaborn.pydata.org) for _nice_ data visualization\n",
    "- [scikit-learn](scikit-learn.org) an extensive machine learning library.\n",
    "- [numpy](numpy.org) - a fundamental maths library best used by people with a strong maths background.  We won't explore it much today, but it does have some useful methods that we'll need.  It underlies all other mathematical and plotting tools that we use in Python.\n",
    "\n",
    "Shortly we'll also by trying out:\n",
    "- [statsmodel](statsmodel.org) - this is another library for doing statistical fitting.  It generates R-like reports.\n",
    "- We'll also being trying out two new parts of scikit-learn sklearn.cross_decomposition and decomposition for PLS and PCA \n",
    "\n",
    "We'll be using scikit-learn over the next few weeks, and it's well worth reading the documentation and high level descriptions.\n",
    "\n",
    "As before, the aim is to get familiar with code-sharing workflows - so we will be doing pair programming for the duration of the day! _You will probably want to take a moment to look at the documentation of the libraries above - especially pandas_\n",
    "\n",
    "The other useful resource is Stack Overflow - if you have a question that sounds like 'how do I do {x}' then someone will probably have answered it on SO. Questions are also tagged by library so if you have a particular pandas question you can do something like going to https://stackoverflow.com/questions/tagged/pandas (just replace the 'pandas' in the URL with whatever library you're trying to use.\n",
    "\n",
    "Generally answers on SO are probably a lot closer to getting you up and running than the documentation. Once you get used to the library then the documentation is generally a quicker reference. We will cover strategies for getting help in class.\n",
    "\n",
    "Topics that we'll be discussing in this session include:\n",
    "Robust Regression - http://scikit-learn.org/stable/modules/linear_model.html#robustness-regression-outliers-and-modeling-errors\n",
    "\n",
    "\n",
    "## Git links\n",
    "\n",
    "We will be working through using GitHub and GitKraken to share code between pairs. We will go through all the workflow in detail in class but here are some useful links for reference:\n",
    "\n",
    "- GitKraken interface basics: https://support.gitkraken.com/start-here/interface\n",
    "- Staging and committing (save current state -> local history): https://support.gitkraken.com/working-with-commits/commits\n",
    "- Pushing and pulling (sync local history <-> GitHub history): https://support.gitkraken.com/working-with-repositories/pushing-and-pulling\n",
    "- Forking and pull requests (request to sync your GitHub history <-> someone else's history - requires a _review_):\n",
    "  - https://help.github.com/articles/about-forks/\n",
    "  - https://help.github.com/articles/creating-a-pull-request-from-a-fork/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:  Apply statsmodel to the synthetic drilling hole data\n",
    "\n",
    "Statsmodel has an API with similarities to scikit-learn, but uses statistical language (particularly as used in financial and economic models) rather than the terminology that is more common in machine learning.  Statsmodel refers to endogeneous and exogeneous variables.  In many ways they reflect the differences in philosophy between how people with a statistics modelling background work, vs people with machine learning/computing backgrounds.  Scikit-learn has a focus on training and validation error curves and cross-validation to choose a model, whereas statsmodel provides metrics for hypothesis tests and goodness-of-fit.\n",
    "\n",
    "We'll briefly look at a typical report that statsmodel generates after fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if using jupyterhub\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from regression_help import create_composition_dataframe, create_observations, create_templates_matrix\n",
    "\n",
    "templates = create_templates_matrix()\n",
    "compositions = create_composition_dataframe(150)\n",
    "observations = create_observations(compositions, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_names = list(compositions.keys()) + ['-']\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, constrained_layout=True)\n",
    "for j in range(3):\n",
    "    for i in range(2):\n",
    "        if j*2 + i < 5:\n",
    "            axs[j, i].plot(templates[:, j*2 + i])\n",
    "            axs[j, i].set_title(template_names[j*2 + i])\n",
    "        else:\n",
    "            axs[j, i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(observations[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = templates\n",
    "y = observations[:, 3]\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.predict(templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this against ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions.loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:  Apply PCA to the synthetic drilling hole data\n",
    "\n",
    "We have just worked through the theory behind principal components analysis.  Let's see how we can use it in scikit-learn.  We have also seen how our drilling data problem has many correlated variables, which we have good reason to expect have a lower-dimensional structure.\n",
    "\n",
    "## Look at the correlation matrix\n",
    "\n",
    "Lets look at the correlation matrix for the original instrument-observed features.  As you've seen, the feature variables are highly correlated with each other.  In real-world situations, if we wanted to use linear least squares to find the underlying templates, this can cause linear least squares to fail.  Particularly as we will often have fewer observations than there are unknown variables (426).  \n",
    "\n",
    "Seaborn's heatmap is useful for showing these correlations visually, but it can be very slow.  Matplotlib's matshow is faster, try Matplotlib if heatmap doesn't work well on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "correlation_matrix = np.corrcoef(X)\n",
    "sns.heatmap(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot all of the observations over each other.\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for observation_idx in range(0, 50):\n",
    "    plt.plot(observations[:,observation_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quick exploratory plot immediately tells us there is lots of structure in this dataset.  There are clearly at least two kinds of sample here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA to observations matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go look at scikit-learn's documentation to check what is the module for PCA and apply it on the observations using 15 components. You'll see that the PCA follows the same API we've used for linear regression, with a model instantiation followed by a call of the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  import \n",
    "\n",
    "pca = \n",
    "pca.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)\n",
    "print(len(pca.components_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops!  Can you see what's wrong here?  The components should have the same length as the orginal observations.  These components have only 150 elements.  This means that the observations array isn't organised properly for PCA fitting.  It thinks that we have ~400 observations, each with 150 features.  To fix this we should transpose the matrix.\n",
    "\n",
    "It's always good to look at the dimensions of our arrays to ensure we're not making trivial but annoying mistakes like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_observations = observations.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the PCA again on the transposed observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the number of features in a component again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!  We clearly have many more elements in these component arrays now.\n",
    "\n",
    "Let's look at the explained variance, as discussed in the Powerpoints.  Intuitively, this sounds like what you want.  Some documentation on the web also suggests that this is what we want. But Python is a living project and this now returns abstract quantities (\"eigenvalues\") that are related to the variances, but are not variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowadays, we should use explained_variance_ratio, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that the first component was able to account for about 86% of the variation, and the two following components account for about 1% and then less than 1% each.\n",
    "\n",
    "PCA has compressed 87% of the variation in ~400 features into just two transformed features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do these principal components look like?\n",
    "plt.plot(pca.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does this compare to our quartz template?  Remember,\n",
    "# with PCA we've only seen the observations.  The PCA transform\n",
    "# didn't know what the templates were beforehand.\n",
    "plt.plot(templates[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the principal components may not find the original templates, but what it does find are patterns that can help distinguish the templates from each other.  Notice how the first three peaks do seem to relate to the first three in the template, though inverted (mathematically, this doesn't matter).  Interestingly there is a fourth peak present.  This is likely because that fourth peak is important for distinguishing quartz from another phase that otherwise looks similar.  Note it has opposite sign to the first three peaks.  It can be very hard (and it's often academic) to interpret qualitatively what the meaning in the components is.  But in this case it does have a clear relevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilithium?\n",
    "plt.plot(pca.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dilithium template\n",
    "plt.plot(templates[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting.  In the mixtures dilithium and quartz often appear together.  The principal component has a fourth peak that is sensitive to the dilithium peak.  The quartz peak was inverted as it was trying to filter it out.\n",
    "\n",
    "Note: During the initial presentation I hadn't looked at it closely enough and thought that the peak was offset a bit.  This happens sometimes with principal components when there are interferences, and the principal component becomes sensitive to a leading or falling edge.  But it doesn't seem to be happening in this particular instance.\n",
    "\n",
    "Let's plot them over each other to be sure -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(templates[:, 1])\n",
    "plt.plot(pca.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the third, kryptonite phase,\n",
    "# followed by the third principal component\n",
    "plt.plot(templates[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.components_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the unobtainium phase, followed by the fourth component\n",
    "plt.plot(templates[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.components_[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better than I expected, for unobtainium.  But there's a good chance that PCA regression will struggle to predict unobtainium well, especially when there isn't very much present.\n",
    "\n",
    "We can plot explained variance like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to hit a sweet spot at about 2 components, and then explained variance only gradually improves after this point.  This is a good result, given that we know that we know these samples only contain four minerals, and all other variance is from noise.\n",
    "\n",
    "How do we look at the transformed data?  We use the transform method to find the \"scores\" associated with each observation.  These are new observations in the new feature space that PCA has found.  Each element in observations_in_pc_space has 15 elements in it, being the reduced feature space.  So we have a new feature space of 15 dimensions, when we used to have 426."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_in_pc_space = pca.transform(transposed_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the first observation in the PC feature space.\n",
    "plt.plot(observations_in_pc_space[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the third observation\n",
    "plt.plot(observations_in_pc_space[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of all of this is to reduce the dimensionality so that we can better see the underlying structure.\n",
    "\n",
    "We'd like to be able to plot the \"scores\" against each other, and look for patterns.\n",
    "\n",
    "That's hard in 15 dimensions, but as we've seen, we can explain most of the variance in only a couple of dimensions.  Let's plot PC1 against PC2 for all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(observations_in_pc_space[:, 0], observations_in_pc_space[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh look!  There are clusters!\n",
    "\n",
    "This tells us that there are three distinct groupings of our samples in the set of 150.  This is based only on the first couple of principal components.\n",
    "\n",
    "What about PC2 and PC3?  Are there any clusters there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:  Look at the Octane dataset\n",
    "\n",
    "Try to study the Octane dataset in the same manner!  You'll need pandas to read the dataset octane.csv from the data folder. You'll need to disregard the columns with the sample names and the octane ratings, as we're only interested in the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open templates from disk, drop the sample names and octane numbers and the\n",
    "# octane observations.\n",
    "octane_dataframe = \n",
    "octane_dataframe = \n",
    "observations = octane_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot all of the observations over each other.\n",
    "for i in range(observations.shape[0]):\n",
    "    plt.plot(observations[i, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit hard to tell from this plot, but there may be a couple of clusters present in this data.\n",
    "\n",
    "Let's look at the principal components. We don't need to transpose these observations, so this real life data is easier to use than the synthetic drillholes! First, create a PCA model, fit it to the observations, and print the explained variance ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the cumulative explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset the first component is able to account for 92.3% of the variance in the dataset!  That's even better than with our synthetic drilling data.  It looks like we need about 4 components before there is little contribution from the remaining components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at that first component\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the second component\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without domain knowledge in the industry, interpreting these shapes is hard, or impossible.  Fortunately, they're usually not what we're interested, and we've done PCA to help us see clusters, or as a transformation prior to applying a machine learning method (such as linear regression in the simplest case). Transform the observations to get their coordinates in the principal components' space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_in_pc_space = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a scatterplot to visualize the first two components as we've done in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting!  It supports and makes more clear that there are likely to be two clusters here.  In this situation domain knowledge is helpful to understand what these two clusters could be.  If we know the row indices we can separate out the observations on the right.  Often just eyeballing (physically, in the plant, or at the instrument) the two groups of samples is enough to reveal why they're different and if the right group should be treated as outlier observations to be removed, or if they're important and central to the process variation being modelled.\n",
    "\n",
    "Let's look at the second and third components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no obvious clustering between the second and third components. How about in the third and fourth components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is clustering in the third and fourth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out which observations are not like the others here.  We can split them by looking at PC4, maybe choosing those that have score more that are less than -0.03 or greater than 0.03.\n",
    "\n",
    "By looking at PC4, and if we had domain knowledge, we may have been able to deduce why these samples are different without further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC4 = observations_in_pc_space[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where returns a \"tuple of arrays\".  This code\n",
    "# will extract the indices of the rows that fit the\n",
    "# \"where\" criteria\n",
    "PC4_big = np.where((PC4 > 0.03))[0]\n",
    "PC4_small = np.where((PC4 < -0.03))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at PC1 too.  The split is obvious at a score of 0.4 on that component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = observations_in_pc_space[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1_strange = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the observation rows that we've extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1_strange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that our strange observations on PC1 have indices: 24, 25, 35, 36, 37 and 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC4_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC4_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting!  On the PC4 axis, our strange observations are:\n",
    "24, 25, 35, 36 and 38.  37 is missing from this set.  But out of curiosity, did we almost get it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC4[37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, it's just strange on PC1.  Let's plot these strange observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for strange_observations in PC1_strange:\n",
    "    plt.plot(observations[strange_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "all_observations = np.arange(0, 39)\n",
    "for normal_observations in np.setdiff1d(all_observations, PC1_strange):\n",
    "    plt.plot(observations[normal_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strange nature of these is quite clear.  What do we do with them is a domain expert question.  Importantly, they really jump out when we look at them with PCA.  For argument's sake, lets call them outliers and say we want to remove them.  We can easily split the outliers from the non-outliers now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = observations[PC1_strange]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_observations = np.arange(0, 39)\n",
    "inliers = observations[np.setdiff1d(all_observations, PC1_strange)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now wanted to create a regression model to predict Octane, we could iterate our PCA process and choose to build the regression model only on the inlier observations.  It's likely to give a better model than the one that uses all observations.  We could also use the original model to identify if new observations are outliers.  For example, using the original 0.4 threshold on PC1.  If a new observation has PC1 (original model) greater than this then we flag it to the user as an outlier, instead of trying to do an Octane prediction.  Perhaps in the Octane context it's an indicator of a serious problem in the petrol production plant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
